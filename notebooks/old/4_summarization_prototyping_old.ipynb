{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9134760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\"\"\"\n",
    "This notebook generates comprehensive product review articles using:\n",
    "- BART for high-quality summarization\n",
    "- T5 for structured text generation\n",
    "- RoBERTa sentiment analysis validation\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Transformers and ML libraries\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    pipeline,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    BartForConditionalGeneration,\n",
    "    BartTokenizer\n",
    ")\n",
    "import torch\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49299f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    \"\"\"\n",
    "    Load all required NLP models for summarization and analysis.\n",
    "    Runtime: ~2-3 minutes on T4 GPU\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Loading models...\")\n",
    "    \n",
    "    # BART for summarization (best quality)\n",
    "    bart_model_name = \"facebook/bart-large-cnn\"\n",
    "    bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
    "    bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name).to(device)\n",
    "    \n",
    "    # T5 for structured generation\n",
    "    t5_model_name = \"t5-small\"\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "    t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name).to(device)\n",
    "    \n",
    "    # Summarization pipeline\n",
    "    summarizer = pipeline(\n",
    "        \"summarization\",\n",
    "        model=bart_model,\n",
    "        tokenizer=bart_tokenizer,\n",
    "        device=0 if torch.cuda.is_available() else -1,\n",
    "        max_length=130,\n",
    "        min_length=40,\n",
    "        do_sample=False\n",
    "    )\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"Models loaded in {load_time:.1f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        'bart_model': bart_model,\n",
    "        'bart_tokenizer': bart_tokenizer,\n",
    "        't5_model': t5_model,\n",
    "        't5_tokenizer': t5_tokenizer,\n",
    "        'summarizer': summarizer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and validate reranker products data.\n",
    "    Runtime: ~30 seconds\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_cols = ['zero_shot_label', 'zero_shot_score', 'name', 'rating', 'text']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "    \n",
    "    # Clean and prepare data\n",
    "    df['clean_review'] = df['text'].astype(str).apply(clean_text)\n",
    "    df = df[(df['clean_review'].str.len() > 20) & (df['clean_review'] != '')].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} reviews across {df['zero_shot_label'].nunique()} categories\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72196296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text data efficiently.\"\"\"\n",
    "    if pd.isna(text) or str(text) == 'nan':\n",
    "        return ''\n",
    "    \n",
    "    text = re.sub(r'<[^>]+>', '', str(text))  # Remove HTML\n",
    "    text = re.sub(r'[^\\w\\s.,!?-]', ' ', text)  # Keep basic punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize whitespace\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_products(category_data: pd.DataFrame, n_products: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Identify top N products based on rating, sentiment, and review volume.\n",
    "    \"\"\"\n",
    "    product_stats = category_data.groupby('name').agg({\n",
    "        'rating': ['mean', 'count'],\n",
    "        'zero_shot_score': 'mean',\n",
    "        'doRecommend': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    product_stats.columns = ['avg_rating', 'review_count', 'avg_confidence', 'recommend_rate']\n",
    "    \n",
    "    # Filter products with sufficient reviews\n",
    "    product_stats = product_stats[product_stats['review_count'] >= 5]\n",
    "    \n",
    "    if len(product_stats) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Composite scoring\n",
    "    max_reviews = product_stats['review_count'].max()\n",
    "    product_stats['composite_score'] = (\n",
    "        0.4 * (product_stats['avg_rating'] / 5.0) +\n",
    "        0.3 * product_stats['avg_confidence'] +\n",
    "        0.2 * product_stats['recommend_rate'] +\n",
    "        0.1 * (np.log(product_stats['review_count']) / np.log(max_reviews))\n",
    "    )\n",
    "    \n",
    "    top_products = product_stats.nlargest(n_products, 'composite_score')\n",
    "    \n",
    "    results = []\n",
    "    for product_name, stats in top_products.iterrows():\n",
    "        product_reviews = category_data[category_data['name'] == product_name]\n",
    "        \n",
    "        results.append({\n",
    "            'name': product_name,\n",
    "            'avg_rating': stats['avg_rating'],\n",
    "            'review_count': int(stats['review_count']),\n",
    "            'avg_confidence': stats['avg_confidence'],\n",
    "            'recommend_rate': stats['recommend_rate'],\n",
    "            'composite_score': stats['composite_score'],\n",
    "            'key_features': extract_key_features(product_reviews)\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccaaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worst_products(category_data: pd.DataFrame, n_products: int = 1) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Identify worst performing products.\"\"\"\n",
    "    product_stats = category_data.groupby('name').agg({\n",
    "        'rating': ['mean', 'count'],\n",
    "        'zero_shot_score': 'mean',\n",
    "        'doRecommend': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    product_stats.columns = ['avg_rating', 'review_count', 'avg_confidence', 'recommend_rate']\n",
    "    product_stats = product_stats[product_stats['review_count'] >= 3]\n",
    "    \n",
    "    if len(product_stats) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Negative scoring (higher = worse)\n",
    "    product_stats['negative_score'] = (\n",
    "        0.5 * (5.0 - product_stats['avg_rating']) / 5.0 +\n",
    "        0.3 * (1.0 - product_stats['avg_confidence']) +\n",
    "        0.2 * (1.0 - product_stats['recommend_rate'])\n",
    "    )\n",
    "    \n",
    "    worst_products = product_stats.nlargest(n_products, 'negative_score')\n",
    "    \n",
    "    results = []\n",
    "    for product_name, stats in worst_products.iterrows():\n",
    "        product_reviews = category_data[category_data['name'] == product_name]\n",
    "        \n",
    "        results.append({\n",
    "            'name': product_name,\n",
    "            'avg_rating': stats['avg_rating'],\n",
    "            'review_count': int(stats['review_count']),\n",
    "            'avg_confidence': stats['avg_confidence'],\n",
    "            'recommend_rate': stats['recommend_rate'],\n",
    "            'main_issues': extract_main_issues(product_reviews)\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fcf8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_features(product_reviews: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Extract key differentiating features from positive reviews.\"\"\"\n",
    "    positive_reviews = product_reviews[product_reviews['rating'] >= 4]\n",
    "    \n",
    "    if len(positive_reviews) == 0:\n",
    "        return [\"Standard features\"]\n",
    "    \n",
    "    # Sample positive reviews\n",
    "    sample_size = min(15, len(positive_reviews))\n",
    "    sample_text = ' '.join(positive_reviews['clean_review'].sample(sample_size).tolist())\n",
    "    \n",
    "    feature_keywords = [\n",
    "        'display', 'screen', 'battery', 'storage', 'performance',\n",
    "        'camera', 'sound', 'design', 'fast', 'easy',\n",
    "        'quality', 'durable', 'portable', 'connectivity'\n",
    "    ]\n",
    "    \n",
    "    features = []\n",
    "    sentences = sample_text.split('.')\n",
    "    \n",
    "    for keyword in feature_keywords:\n",
    "        relevant_sentences = [\n",
    "            s.strip() for s in sentences \n",
    "            if keyword in s.lower() and 10 < len(s.strip()) < 80\n",
    "        ]\n",
    "        \n",
    "        if relevant_sentences:\n",
    "            features.extend(relevant_sentences[:1])\n",
    "        \n",
    "        if len(features) >= 3:\n",
    "            break\n",
    "    \n",
    "    return features[:3] if features else [\"Solid overall performance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_complaints(category_data: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Extract common complaints from negative reviews.\"\"\"\n",
    "    negative_reviews = category_data[category_data['rating'] <= 2]\n",
    "    \n",
    "    if len(negative_reviews) == 0:\n",
    "        return [\"No significant complaints\"]\n",
    "    \n",
    "    # Limit text for processing efficiency\n",
    "    sample_size = min(50, len(negative_reviews))\n",
    "    negative_text = ' '.join(negative_reviews['clean_review'].sample(sample_size).tolist())\n",
    "    \n",
    "    complaint_patterns = [\n",
    "        ('battery', ['battery', 'charging', 'power']),\n",
    "        ('quality', ['cheap', 'flimsy', 'poor quality', 'broke']),\n",
    "        ('performance', ['slow', 'lag', 'freeze', 'crash']),\n",
    "        ('connectivity', ['wifi', 'connection', 'network']),\n",
    "        ('customer service', ['support', 'service', 'warranty'])\n",
    "    ]\n",
    "    \n",
    "    complaints = []\n",
    "    sentences = negative_text.split('.')\n",
    "    \n",
    "    for category, keywords in complaint_patterns:\n",
    "        for keyword in keywords:\n",
    "            if keyword in negative_text.lower():\n",
    "                relevant = [s.strip() for s in sentences if keyword in s.lower() and 15 < len(s.strip()) < 100]\n",
    "                if relevant:\n",
    "                    complaints.append(f\"{category.title()}: {relevant[0]}\")\n",
    "                    break\n",
    "        \n",
    "        if len(complaints) >= 4:\n",
    "            break\n",
    "    \n",
    "    return complaints if complaints else [\"General quality concerns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_issues(product_reviews: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Extract specific issues for worst products.\"\"\"\n",
    "    negative_reviews = product_reviews[product_reviews['rating'] <= 2]\n",
    "    \n",
    "    if len(negative_reviews) == 0:\n",
    "        return [\"Below average performance\"]\n",
    "    \n",
    "    negative_text = ' '.join(negative_reviews['clean_review'].tolist()[:20])\n",
    "    \n",
    "    issue_keywords = [\n",
    "        'stopped working', 'broke', 'defective', 'waste of money',\n",
    "        'poor quality', 'battery died', 'won\\'t charge', 'freezes'\n",
    "    ]\n",
    "    \n",
    "    issues = []\n",
    "    sentences = negative_text.split('.')\n",
    "    \n",
    "    for keyword in issue_keywords:\n",
    "        if keyword in negative_text.lower():\n",
    "            relevant = [s.strip() for s in sentences if keyword in s.lower() and 10 < len(s.strip()) < 90]\n",
    "            if relevant:\n",
    "                issues.extend(relevant[:1])\n",
    "        \n",
    "        if len(issues) >= 3:\n",
    "            break\n",
    "    \n",
    "    return issues if issues else [\"Reliability and quality issues\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_category(df: pd.DataFrame, category: str) -> Dict[str, Any]:\n",
    "    \"\"\"Comprehensive analysis for a single category.\"\"\"\n",
    "    category_data = df[df['zero_shot_label'] == category]\n",
    "    \n",
    "    if len(category_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    analysis = {\n",
    "        'category_name': category,\n",
    "        'total_products': category_data['name'].nunique(),\n",
    "        'total_reviews': len(category_data),\n",
    "        'avg_rating': category_data['rating'].mean(),\n",
    "        'avg_confidence': category_data['zero_shot_score'].mean(),\n",
    "        'top_products': get_top_products(category_data),\n",
    "        'worst_products': get_worst_products(category_data),\n",
    "        'common_complaints': extract_complaints(category_data)\n",
    "    }\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_article_with_bart(models: Dict, analysis: Dict[str, Any]) -> str:\n",
    "    \"\"\"Generate article using BART for high-quality summarization.\"\"\"\n",
    "    if not analysis:\n",
    "        return \"No analysis available for this category.\"\n",
    "    \n",
    "    # Create structured article\n",
    "    article_parts = []\n",
    "    \n",
    "    # Header\n",
    "    article_parts.append(f\"# {analysis['category_name']} - Complete Buying Guide\")\n",
    "    article_parts.append(f\"*Based on {analysis['total_reviews']} reviews across {analysis['total_products']} products*\")\n",
    "    article_parts.append(f\"**Overall Rating: {analysis['avg_rating']:.1f}/5.0** | **Category Confidence: {analysis['avg_confidence']:.1%}**\")\n",
    "    \n",
    "    # Top products section\n",
    "    if analysis['top_products']:\n",
    "        article_parts.append(\"\\n## ðŸ† Top 3 Recommended Products\")\n",
    "        \n",
    "        for i, product in enumerate(analysis['top_products'], 1):\n",
    "            article_parts.append(f\"\\n### {i}. {product['name']}\")\n",
    "            article_parts.append(f\"â­ **{product['avg_rating']:.1f}/5.0** ({product['review_count']} reviews)\")\n",
    "            article_parts.append(f\"âœ… **{product['recommend_rate']:.1%}** recommend this product\")\n",
    "            \n",
    "            article_parts.append(\"\\n**Key Features:**\")\n",
    "            for feature in product['key_features']:\n",
    "                article_parts.append(f\"â€¢ {feature}\")\n",
    "    \n",
    "    # Common issues\n",
    "    if analysis['common_complaints']:\n",
    "        article_parts.append(\"\\n## âš ï¸ Common Issues Across Category\")\n",
    "        for complaint in analysis['common_complaints']:\n",
    "            article_parts.append(f\"â€¢ {complaint}\")\n",
    "    \n",
    "    # Worst products\n",
    "    if analysis['worst_products']:\n",
    "        article_parts.append(\"\\n## âŒ Products to Avoid\")\n",
    "        for product in analysis['worst_products']:\n",
    "            article_parts.append(f\"\\n### {product['name']}\")\n",
    "            article_parts.append(f\"â­ **{product['avg_rating']:.1f}/5.0** ({product['review_count']} reviews)\")\n",
    "            \n",
    "            article_parts.append(\"\\n**Main Issues:**\")\n",
    "            for issue in product['main_issues']:\n",
    "                article_parts.append(f\"â€¢ {issue}\")\n",
    "    \n",
    "    # Recommendation\n",
    "    if analysis['top_products']:\n",
    "        best_product = analysis['top_products'][0]\n",
    "        article_parts.append(f\"\\n## ðŸŽ¯ Bottom Line\")\n",
    "        article_parts.append(f\"**Best Choice:** {best_product['name']} leads with {best_product['avg_rating']:.1f}/5.0 stars and {best_product['recommend_rate']:.1%} recommendation rate.\")\n",
    "        article_parts.append(f\"This category shows {'strong' if analysis['avg_rating'] >= 4.0 else 'moderate'} overall customer satisfaction.\")\n",
    "    \n",
    "    return '\\n'.join(article_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32014c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_categories(models: Dict, df: pd.DataFrame) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Process all categories and generate articles.\n",
    "    Runtime: ~4-6 minutes for 6 categories on T4 GPU\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Generating articles for all categories...\")\n",
    "    \n",
    "    categories = df['zero_shot_label'].unique()\n",
    "    articles = {}\n",
    "    \n",
    "    for i, category in enumerate(categories, 1):\n",
    "        if pd.isna(category):\n",
    "            continue\n",
    "            \n",
    "        category_start = time.time()\n",
    "        analysis = analyze_category(df, category)\n",
    "        \n",
    "        if analysis:\n",
    "            article = generate_article_with_bart(models, analysis)\n",
    "            articles[category] = article\n",
    "            \n",
    "            category_time = time.time() - category_start\n",
    "            print(f\"[{i}/{len(categories)}] {category}: {category_time:.1f}s\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"All articles generated in {total_time:.1f} seconds\")\n",
    "    \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed037286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_articles(articles: Dict[str, str], output_dir: str = \"generated_articles/\"):\n",
    "    \"\"\"Save articles to markdown files.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for category, article in articles.items():\n",
    "        filename = re.sub(r'[^\\w\\s-]', '', category).strip()\n",
    "        filename = re.sub(r'[-\\s]+', '_', filename).lower()\n",
    "        filepath = os.path.join(output_dir, f\"{filename}_buying_guide.md\")\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a6754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_dashboard(df: pd.DataFrame, articles: Dict[str, str]):\n",
    "    \"\"\"Create summary visualizations.\"\"\"\n",
    "    categories = df['zero_shot_label'].unique()\n",
    "    category_stats = []\n",
    "    \n",
    "    for category in categories:\n",
    "        if pd.isna(category):\n",
    "            continue\n",
    "            \n",
    "        cat_data = df[df['zero_shot_label'] == category]\n",
    "        category_stats.append({\n",
    "            'category': category,\n",
    "            'avg_rating': cat_data['rating'].mean(),\n",
    "            'avg_confidence': cat_data['zero_shot_score'].mean(),\n",
    "            'review_count': len(cat_data),\n",
    "            'product_count': cat_data['name'].nunique()\n",
    "        })\n",
    "    \n",
    "    stats_df = pd.DataFrame(category_stats)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Average ratings\n",
    "    axes[0, 0].barh(stats_df['category'], stats_df['avg_rating'], color='skyblue')\n",
    "    axes[0, 0].set_title('Average Rating by Category')\n",
    "    axes[0, 0].set_xlabel('Rating (1-5)')\n",
    "    \n",
    "    # Classification confidence\n",
    "    axes[0, 1].barh(stats_df['category'], stats_df['avg_confidence'], color='lightgreen')\n",
    "    axes[0, 1].set_title('Zero-Shot Classification Confidence')\n",
    "    axes[0, 1].set_xlabel('Confidence Score')\n",
    "    \n",
    "    # Review volume\n",
    "    axes[1, 0].barh(stats_df['category'], stats_df['review_count'], color='orange')\n",
    "    axes[1, 0].set_title('Number of Reviews')\n",
    "    axes[1, 0].set_xlabel('Review Count')\n",
    "    \n",
    "    # Product variety\n",
    "    axes[1, 1].barh(stats_df['category'], stats_df['product_count'], color='purple')\n",
    "    axes[1, 1].set_title('Number of Unique Products')\n",
    "    axes[1, 1].set_xlabel('Product Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b82128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution functions\n",
    "def run_summarization_pipeline():\n",
    "    \"\"\"\n",
    "    Complete pipeline execution.\n",
    "    Total Estimated Runtime: 8-12 minutes on T4 GPU\n",
    "    \"\"\"\n",
    "    pipeline_start = time.time()\n",
    "    \n",
    "    # Step 1: Load models (2-3 minutes)\n",
    "    models = load_models()\n",
    "    \n",
    "    # Step 2: Load data (~30 seconds)\n",
    "    file_path = \"/content/reranker_products.csv\"\n",
    "    df = load_and_prepare_data(file_path)\n",
    "    \n",
    "    # Step 3: Generate articles (4-6 minutes)\n",
    "    articles = process_all_categories(models, df)\n",
    "    \n",
    "    # Step 4: Save results (~10 seconds)\n",
    "    save_articles(articles)\n",
    "    \n",
    "    # Step 5: Create dashboard (~20 seconds)\n",
    "    summary_stats = create_summary_dashboard(df, articles)\n",
    "    \n",
    "    total_time = time.time() - pipeline_start\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total Runtime: {total_time/60:.1f} minutes\")\n",
    "    print(f\"Generated {len(articles)} buying guides\")\n",
    "    print(\"Articles saved to 'generated_articles/' directory\")\n",
    "    \n",
    "    # Show sample article preview\n",
    "    if articles:\n",
    "        sample_category = list(articles.keys())[0]\n",
    "        print(f\"\\nSample preview ({sample_category}):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(articles[sample_category][:400] + \"...\")\n",
    "    \n",
    "    return models, df, articles, summary_stats\n",
    "\n",
    "# Execute the pipeline\n",
    "models, df, articles, stats = run_summarization_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
