{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46c5014",
   "metadata": {},
   "source": [
    "## Product Categorization and Insights\n",
    "This notebook tries to simplify the dataset by clustering it into 6 categories using a zero-shot attempt with the bge-reranker model\n",
    "and give valuable insights into the data\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a4863",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyngrok'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgetpass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getpass\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyngrok\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ngrok\n\u001b[32m     14\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyngrok'"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "import warnings\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sentence_transformers import CrossEncoder\n",
    "import re\n",
    "from getpass import getpass\n",
    "from collections import Counter\n",
    "from pyngrok import ngrok\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb4680",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa794d5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "file_path = \"/content/Datafiniti_with_sentiments.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def create_text_features(row: pd.Series) -> str:\n",
    "    \"\"\"Extracts and cleans the product name from a DataFrame row.\"\"\"\n",
    "    name = row.get(\"name\", \"\")\n",
    "    if pd.notna(name) and str(name).strip():\n",
    "        return str(name).strip().lower()\n",
    "    return \"\"\n",
    "\n",
    "df[\"product_name_clean\"] = df.apply(create_text_features, axis=1)\n",
    "df = df[df[\"product_name_clean\"].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "sentiment_mapping = {\"Positive\": 1.0, \"Neutral\": 0.5, \"Negative\": 0.0}\n",
    "if \"predicted_sentiment_roberta\" in df.columns:\n",
    "    df[\"predicted_sentiment_roberta\"] = df[\"predicted_sentiment_roberta\"].map(sentiment_mapping)\n",
    "else:\n",
    "    df[\"predicted_sentiment_roberta\"] = np.nan\n",
    "\n",
    "print(f\"Dataset size after cleaning: {len(df)} reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfedd2d5",
   "metadata": {},
   "source": [
    "## Zero-Shot Product Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5697723",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Fire Tablet Special\",\n",
    "    \"AmazonBasics Performance Alkaline(Batteries)\",\n",
    "    \"Anon/Uncategorized\",\n",
    "    \"Echo White Amazon\",\n",
    "    \"Fire Kids Edition\",\n",
    "    \"Fire Amazon\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_reranker(texts: list[str], labels: list[str], model_name: str) -> tuple[list[str], list[float]]:\n",
    "    \"\"\"\n",
    "    Classifies texts into the most relevant label using a CrossEncoder reranker model.\n",
    "    \"\"\"\n",
    "    model = CrossEncoder(model_name)\n",
    "    pairs = [(text, label) for text in texts for label in labels]\n",
    "    scores = model.predict(pairs).reshape(len(texts), len(labels))\n",
    "    best_indices = np.argmax(scores, axis=1)\n",
    "    pred_labels = [labels[i] for i in best_indices]\n",
    "    pred_scores = [scores[i, best_indices[i]] for i in range(len(texts))]\n",
    "    return pred_labels, pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_category_stats(df: pd.DataFrame, cat_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes summary statistics for each category.\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for cat, g in df.groupby(cat_col):\n",
    "        row = {\n",
    "            \"category\": cat,\n",
    "            \"count\": len(g),\n",
    "            \"avg_sentiment\": g[\"predicted_sentiment_roberta\"].mean(),\n",
    "            \"positive_pct\": (g[\"predicted_sentiment_roberta\"] > 0.5).mean() * 100,\n",
    "            \"avg_confidence\": g[\"zero_shot_score\"].mean(),\n",
    "        }\n",
    "        if \"rating\" in g.columns:\n",
    "            row[\"avg_rating\"] = g[\"rating\"].mean()\n",
    "            row[\"high_rating_pct\"] = (g[\"rating\"] >= 4).mean() * 100\n",
    "        if \"doRecommend\" in g.columns:\n",
    "            row[\"recommend_pct\"] = g[\"doRecommend\"].mean() * 100\n",
    "        stats.append(row)\n",
    "    return pd.DataFrame(stats).sort_values(\"count\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8505ede",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "preds, scores = classify_with_reranker(\n",
    "    df[\"product_name_clean\"].tolist(),\n",
    "    labels=labels,\n",
    "    model_name=\"BAAI/bge-reranker-v2-m3\",\n",
    ")\n",
    "\n",
    "df[\"zero_shot_label\"] = preds\n",
    "df[\"zero_shot_score\"] = scores\n",
    "cat_results = compute_category_stats(df, \"zero_shot_label\")\n",
    "cat_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf2d85",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d056c72e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"category\", y=\"count\", data=cat_results)\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.title(\"Review Distribution per Category\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"category\", y=\"avg_sentiment\", data=cat_results)\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.title(\"Average Sentiment per Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92811554",
   "metadata": {},
   "source": [
    "## Deep Dive into Product Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_products = df[\"product_name_clean\"].value_counts().head(3)\n",
    "print(\"Top 3 Products:\")\n",
    "print(top_products)\n",
    "\n",
    "top_products_stats = df[df[\"product_name_clean\"].isin(top_products.index)].groupby(\"product_name_clean\").agg({\n",
    "    \"predicted_sentiment_roberta\": \"mean\",\n",
    "    \"rating\": \"mean\" if \"rating\" in df.columns else \"first\",\n",
    "    \"doRecommend\": \"mean\" if \"doRecommend\" in df.columns else \"first\",\n",
    "    \"zero_shot_label\": \"first\"\n",
    "})\n",
    "top_products_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739bc1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def extract_complaints(subset: pd.DataFrame, top_n: int = 10) -> list:\n",
    "    \"\"\"Extracts the top N most common words from negative reviews.\"\"\"\n",
    "    texts = \" \".join(subset.loc[subset[\"predicted_sentiment_roberta\"] == 0.0, \"text\"].dropna().astype(str))\n",
    "    words = re.findall(r\"\\b\\w{3,}\\b\", texts.lower())\n",
    "    return Counter(words).most_common(top_n)\n",
    "\n",
    "for prod in top_products.index:\n",
    "    complaints = extract_complaints(df[df[\"product_name_clean\"] == prod])\n",
    "    print(f\"\\nTop complaints for {prod}:\")\n",
    "    print(complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3d719",
   "metadata": {},
   "source": [
    "## Identifying the Worst Performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cccc538",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "worst_products = (\n",
    "    df.groupby([\"zero_shot_label\", \"product_name_clean\"])\n",
    "    .agg(avg_sentiment=(\"predicted_sentiment_roberta\", \"mean\"), count=(\"product_name_clean\", \"size\"))\n",
    "    .reset_index()\n",
    "    .sort_values([\"zero_shot_label\", \"avg_sentiment\"])\n",
    ")\n",
    "\n",
    "worst_by_cat = worst_products.groupby(\"zero_shot_label\").first().reset_index()\n",
    "print(\"Worst products per category:\")\n",
    "worst_by_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5e48a",
   "metadata": {},
   "source": [
    "## MLflow Logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to MLflow\n",
    "# This section is commented out to prevent running without a configured MLflow server.\n",
    "# !mlflow ui --port 5000 &\n",
    "# from pyngrok import ngrok\n",
    "# from getpass import getpass\n",
    "# ngrok.kill()\n",
    "# NGROK_AUTH_TOKEN = getpass(\"Enter your ngrok authtoken: \")\n",
    "# ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "# public_url = ngrok.connect(addr=\"5000\", proto=\"http\")\n",
    "# print(\"MLflow Tracking UI:\", public_url)\n",
    "\n",
    "mlflow.set_experiment(\"Product Categorization with Reranker\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"zero_shot_reranker\"):\n",
    "    mlflow.log_param(\"model\", \"BAAI/bge-reranker-v2-m3\")\n",
    "    mlflow.log_param(\"candidate_labels\", labels)\n",
    "    for _, r in cat_results.iterrows():\n",
    "        sanitized_category = re.sub(r'[^a-zA-Z0-9_.-]', '_', str(r['category']).replace(' ', '_'))\n",
    "        prefix = f\"cat_{sanitized_category}\"\n",
    "        mlflow.log_metric(f\"{prefix}_count\", int(r[\"count\"]))\n",
    "        if not np.isnan(r[\"avg_sentiment\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_avg_sentiment\", float(r[\"avg_sentiment\"]))\n",
    "            mlflow.log_metric(f\"{prefix}_positive_pct\", float(r[\"positive_pct\"]))\n",
    "        if not np.isnan(r[\"avg_confidence\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_avg_confidence\", float(r[\"avg_confidence\"]))\n",
    "        if \"avg_rating\" in r and not pd.isna(r[\"avg_rating\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_avg_rating\", float(r[\"avg_rating\"]))\n",
    "        if \"high_rating_pct\" in r and not pd.isna(r[\"high_rating_pct\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_high_rating_pct\", float(r[\"high_rating_pct\"]))\n",
    "        if \"recommend_pct\" in r and not pd.isna(r[\"recommend_pct\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_recommend_pct\", float(r[\"recommend_pct\"]))\n",
    "\n",
    "    df.to_csv(\"reranker_products.csv\", index=False)\n",
    "    cat_results.to_csv(\"reranker_stats.csv\", index=False)\n",
    "    mlflow.log_artifact(\"reranker_products.csv\")\n",
    "    mlflow.log_artifact(\"reranker_stats.csv\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "project_nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
