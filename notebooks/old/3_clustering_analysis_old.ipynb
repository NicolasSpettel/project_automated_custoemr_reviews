{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df68f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "# Cell 1: Imports\n",
    "import warnings\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load & preprocess data\n",
    "file_path = \"/content/Datafiniti_with_sentiments.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def create_text_features(row: pd.Series) -> str:\n",
    "    name = row.get(\"name\", \"\")\n",
    "    if pd.notna(name) and str(name) != \"nan\":\n",
    "        return str(name).strip().lower()\n",
    "    return \"\"\n",
    "\n",
    "df[\"product_name_clean\"] = df.apply(create_text_features, axis=1)\n",
    "df = df[df[\"product_name_clean\"].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "sentiment_mapping = {\"Positive\": 1.0, \"Neutral\": 0.5, \"Negative\": 0.0}\n",
    "if \"predicted_sentiment_roberta\" in df.columns:\n",
    "    df[\"predicted_sentiment_roberta\"] = df[\"predicted_sentiment_roberta\"].map(sentiment_mapping)\n",
    "else:\n",
    "    df[\"predicted_sentiment_roberta\"] = np.nan\n",
    "\n",
    "print(f\"Dataset size after cleaning: {len(df)} reviews\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define categories and helper functions\n",
    "labels = [\n",
    "    \"Fire Tablet Special\",\n",
    "    \"AmazonBasics Performance Alkaline(Batteries)\",\n",
    "    \"Anon/Uncategorized\",\n",
    "    \"Echo White Amazon\",\n",
    "    \"Fire Kids Edition\",\n",
    "    \"Fire Amazon\",\n",
    "]\n",
    "\n",
    "def classify_with_reranker(texts: list[str], labels: list[str], model_name: str) -> tuple[list[str], list[float]]:\n",
    "    model = CrossEncoder(model_name)\n",
    "    pairs = []\n",
    "    idx_map = []\n",
    "    for i, t in enumerate(texts):\n",
    "        for j, l in enumerate(labels):\n",
    "            pairs.append((t, l))\n",
    "            idx_map.append((i, j))\n",
    "    scores = model.predict(pairs)\n",
    "    pred_labels, pred_scores = [], []\n",
    "    for i in range(len(texts)):\n",
    "        label_scores = [(labels[j], scores[k]) for k, (ti, j) in enumerate(idx_map) if ti == i]\n",
    "        best_label, best_score = max(label_scores, key=lambda x: x[1])\n",
    "        pred_labels.append(best_label)\n",
    "        pred_scores.append(float(best_score))\n",
    "    return pred_labels, pred_scores\n",
    "\n",
    "def compute_category_stats(df: pd.DataFrame, cat_col: str) -> pd.DataFrame:\n",
    "    stats = []\n",
    "    for cat, g in df.groupby(cat_col):\n",
    "        row = {\n",
    "            \"category\": cat,\n",
    "            \"count\": len(g),\n",
    "            \"avg_sentiment\": g[\"predicted_sentiment_roberta\"].mean(),\n",
    "            \"positive_pct\": (g[\"predicted_sentiment_roberta\"] > 0.5).mean() * 100,\n",
    "            \"avg_confidence\": g[\"zero_shot_score\"].mean(),\n",
    "        }\n",
    "        if \"rating\" in g.columns:\n",
    "            row[\"avg_rating\"] = g[\"rating\"].mean()\n",
    "            row[\"high_rating_pct\"] = (g[\"rating\"] >= 4).mean() * 100\n",
    "        if \"doRecommend\" in g.columns:\n",
    "            row[\"recommend_pct\"] = g[\"doRecommend\"].mean() * 100\n",
    "        stats.append(row)\n",
    "    return pd.DataFrame(stats).sort_values(\"count\", ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8750f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Run zero-shot classification\n",
    "preds, scores = classify_with_reranker(\n",
    "    df[\"product_name_clean\"].tolist(),\n",
    "    labels=labels,\n",
    "    model_name=\"BAAI/bge-reranker-v2-m3\",\n",
    ")\n",
    "\n",
    "df[\"zero_shot_label\"] = preds\n",
    "df[\"zero_shot_score\"] = scores\n",
    "cat_results = compute_category_stats(df, \"zero_shot_label\")\n",
    "cat_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a52bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui --port 5000 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d714751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "from getpass import getpass\n",
    "\n",
    "ngrok.kill()  # Terminate any existing tunnels\n",
    "NGROK_AUTH_TOKEN = getpass(\"Enter your ngrok authtoken: \")\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "public_url = ngrok.connect(addr=\"5000\", proto=\"http\")\n",
    "print(\"MLflow Tracking UI:\", public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d042152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Cell 5: Log to MLflow\n",
    "mlflow.set_experiment(\"Product Categorization with Reranker\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"zero_shot_reranker\"):\n",
    "    mlflow.log_param(\"model\", \"BAAI/bge-reranker-v2-m3\")\n",
    "    mlflow.log_param(\"candidate_labels\", labels)\n",
    "    for _, r in cat_results.iterrows():\n",
    "\n",
    "        # Add the sanitization line here ⬇️\n",
    "        sanitized_category = re.sub(r'[^a-zA-Z0-9_.-]', '_', str(r['category']).replace(' ', '_'))\n",
    "\n",
    "        # Use the sanitized variable to create the prefix\n",
    "        prefix = f\"cat_{sanitized_category}\"\n",
    "\n",
    "        mlflow.log_metric(f\"{prefix}_count\", int(r[\"count\"]))\n",
    "        if not np.isnan(r[\"avg_sentiment\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_avg_sentiment\", float(r[\"avg_sentiment\"]))\n",
    "            mlflow.log_metric(f\"{prefix}_positive_pct\", float(r[\"positive_pct\"]))\n",
    "        if not np.isnan(r[\"avg_confidence\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_avg_confidence\", float(r[\"avg_confidence\"]))\n",
    "        if \"avg_rating\" in r and not pd.isna(r[\"avg_rating\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_avg_rating\", float(r[\"avg_rating\"]))\n",
    "        if \"high_rating_pct\" in r and not pd.isna(r[\"high_rating_pct\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_high_rating_pct\", float(r[\"high_rating_pct\"]))\n",
    "        if \"recommend_pct\" in r and not pd.isna(r[\"recommend_pct\"]):\n",
    "            mlflow.log_metric(f\"{prefix}_recommend_pct\", float(r[\"recommend_pct\"]))\n",
    "\n",
    "    df.to_csv(\"reranker_products.csv\", index=False)\n",
    "    cat_results.to_csv(\"reranker_stats.csv\", index=False)\n",
    "    mlflow.log_artifact(\"reranker_products.csv\")\n",
    "    mlflow.log_artifact(\"reranker_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Visualization\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"category\", y=\"count\", data=cat_results)\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.title(\"Review Distribution per Category\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"category\", y=\"avg_sentiment\", data=cat_results)\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.title(\"Average Sentiment per Category\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037857a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Insights\n",
    "\n",
    "# Top 3 products by review volume\n",
    "top_products = df[\"product_name_clean\"].value_counts().head(5)\n",
    "print(\"Top 3 Products:\")\n",
    "print(top_products)\n",
    "\n",
    "# Compare differences (ratings, sentiment, recommend %)\n",
    "top_products_stats = df[df[\"product_name_clean\"].isin(top_products.index)].groupby(\"product_name_clean\").agg({\n",
    "    \"predicted_sentiment_roberta\": \"mean\",\n",
    "    \"rating\": \"mean\" if \"rating\" in df.columns else \"first\",\n",
    "    \"doRecommend\": \"mean\" if \"doRecommend\" in df.columns else \"first\",\n",
    "    \"zero_shot_label\": \"first\"\n",
    "})\n",
    "top_products_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Top complaints per top products (most common negative words)\n",
    "from collections import Counter\n",
    "\n",
    "def extract_complaints(subset: pd.DataFrame, top_n=10):\n",
    "    texts = \" \".join(subset.loc[subset[\"predicted_sentiment_roberta\"] == 0.0, \"text\"].dropna().astype(str))\n",
    "    words = re.findall(r\"\\b\\w{3,}\\b\", texts.lower())\n",
    "    return Counter(words).most_common(top_n)\n",
    "\n",
    "for prod in top_products.index:\n",
    "    complaints = extract_complaints(df[df[\"product_name_clean\"] == prod])\n",
    "    print(f\"\\nTop complaints for {prod}:\")\n",
    "    print(complaints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Worst product in each category\n",
    "worst_products = (\n",
    "    df.groupby([\"zero_shot_label\", \"product_name_clean\"])\n",
    "    .agg(avg_sentiment=(\"predicted_sentiment_roberta\", \"mean\"), count=(\"product_name_clean\", \"size\"))\n",
    "    .reset_index()\n",
    "    .sort_values([\"zero_shot_label\", \"avg_sentiment\"])\n",
    ")\n",
    "\n",
    "worst_by_cat = worst_products.groupby(\"zero_shot_label\").first().reset_index()\n",
    "print(\"Worst products per category:\")\n",
    "worst_by_cat\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
