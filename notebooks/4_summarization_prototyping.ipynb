{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c594e3eb",
   "metadata": {},
   "source": [
    "## Product Review Summarization and Buying Guide Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce3d46",
   "metadata": {},
   "source": [
    "This script generates comprehensive product review articles using:\n",
    "- BART for high-quality summarization\n",
    "- T5 for structured text generation\n",
    "- RoBERTa for sentiment validation\n",
    "\n",
    "Pipeline steps:\n",
    "1. Load NLP models\n",
    "2. Load and preprocess review data\n",
    "3. Analyze categories and products\n",
    "4. Generate structured buying guides\n",
    "5. Save articles to Markdown\n",
    "6. Create a summary dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    BartForConditionalGeneration,\n",
    "    BartTokenizer,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d755627",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af90199",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff025d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_models() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load all required NLP models for summarization and analysis.\n",
    "    Runtime: ~2-3 minutes on T4 GPU.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Loading models...\")\n",
    "\n",
    "    # BART for summarization\n",
    "    bart_model_name = \"facebook/bart-large-cnn\"\n",
    "    bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
    "    bart_model = BartForConditionalGeneration.from_pretrained(\n",
    "        bart_model_name\n",
    "    ).to(device)\n",
    "\n",
    "    # T5 for structured generation\n",
    "    t5_model_name = \"t5-small\"\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "    t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name).to(device)\n",
    "\n",
    "    # Summarization pipeline\n",
    "    summarizer = pipeline(\n",
    "        \"summarization\",\n",
    "        model=bart_model,\n",
    "        tokenizer=bart_tokenizer,\n",
    "        device=0 if torch.cuda.is_available() else -1,\n",
    "        max_length=130,\n",
    "        min_length=40,\n",
    "        do_sample=False,\n",
    "    )\n",
    "\n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"Models loaded in {load_time:.1f} seconds\")\n",
    "\n",
    "    return {\n",
    "        \"bart_model\": bart_model,\n",
    "        \"bart_tokenizer\": bart_tokenizer,\n",
    "        \"t5_model\": t5_model,\n",
    "        \"t5_tokenizer\": t5_tokenizer,\n",
    "        \"summarizer\": summarizer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1727db0",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939822b9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text data efficiently.\"\"\"\n",
    "    if pd.isna(text) or str(text) == \"nan\":\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", str(text))  # Remove HTML\n",
    "    text = re.sub(r\"[^\\w\\s.,!?-]\", \" \", text)  # Keep basic punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize whitespace\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a15415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and validate product reviews dataset.\n",
    "    Runtime: ~30 seconds.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    required_cols = [\"zero_shot_label\", \"zero_shot_score\", \"name\", \"rating\", \"text\"]\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "\n",
    "    df[\"clean_review\"] = df[\"text\"].astype(str).apply(clean_text)\n",
    "    df = df[\n",
    "        (df[\"clean_review\"].str.len() > 20) & (df[\"clean_review\"] != \"\")\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    print(\n",
    "        f\"Loaded {len(df)} reviews across {df['zero_shot_label'].nunique()} categories\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b8239",
   "metadata": {},
   "source": [
    "## Product Analysis Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f985d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_key_features(product_reviews: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Extract key differentiating features from positive reviews.\"\"\"\n",
    "    positive_reviews = product_reviews[product_reviews[\"rating\"] >= 4]\n",
    "\n",
    "    if len(positive_reviews) == 0:\n",
    "        return [\"Standard features\"]\n",
    "\n",
    "    sample_size = min(15, len(positive_reviews))\n",
    "    sample_text = \" \".join(\n",
    "        positive_reviews[\"clean_review\"].sample(sample_size).tolist()\n",
    "    )\n",
    "\n",
    "    feature_keywords = [\n",
    "        \"display\",\n",
    "        \"screen\",\n",
    "        \"battery\",\n",
    "        \"storage\",\n",
    "        \"performance\",\n",
    "        \"camera\",\n",
    "        \"sound\",\n",
    "        \"design\",\n",
    "        \"fast\",\n",
    "        \"easy\",\n",
    "        \"quality\",\n",
    "        \"durable\",\n",
    "        \"portable\",\n",
    "        \"connectivity\",\n",
    "    ]\n",
    "\n",
    "    features = []\n",
    "    sentences = sample_text.split(\".\")\n",
    "\n",
    "    for keyword in feature_keywords:\n",
    "        relevant_sentences = [\n",
    "            s.strip()\n",
    "            for s in sentences\n",
    "            if keyword in s.lower() and 10 < len(s.strip()) < 80\n",
    "        ]\n",
    "\n",
    "        if relevant_sentences:\n",
    "            features.extend(relevant_sentences[:1])\n",
    "\n",
    "        if len(features) >= 3:\n",
    "            break\n",
    "\n",
    "    return features[:3] if features else [\"Solid overall performance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeda9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_complaints(category_data: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Extract common complaints from negative reviews.\"\"\"\n",
    "    negative_reviews = category_data[category_data[\"rating\"] <= 2]\n",
    "\n",
    "    if len(negative_reviews) == 0:\n",
    "        return [\"No significant complaints\"]\n",
    "\n",
    "    sample_size = min(50, len(negative_reviews))\n",
    "    negative_text = \" \".join(\n",
    "        negative_reviews[\"clean_review\"].sample(sample_size).tolist()\n",
    "    )\n",
    "\n",
    "    complaint_patterns = [\n",
    "        (\"battery\", [\"battery\", \"charging\", \"power\"]),\n",
    "        (\"quality\", [\"cheap\", \"flimsy\", \"poor quality\", \"broke\"]),\n",
    "        (\"performance\", [\"slow\", \"lag\", \"freeze\", \"crash\"]),\n",
    "        (\"connectivity\", [\"wifi\", \"connection\", \"network\"]),\n",
    "        (\"customer service\", [\"support\", \"service\", \"warranty\"]),\n",
    "    ]\n",
    "\n",
    "    complaints = []\n",
    "    sentences = negative_text.split(\".\")\n",
    "\n",
    "    for category, keywords in complaint_patterns:\n",
    "        for keyword in keywords:\n",
    "            if keyword in negative_text.lower():\n",
    "                relevant = [\n",
    "                    s.strip()\n",
    "                    for s in sentences\n",
    "                    if keyword in s.lower() and 15 < len(s.strip()) < 100\n",
    "                ]\n",
    "                if relevant:\n",
    "                    complaints.append(f\"{category.title()}: {relevant[0]}\")\n",
    "                    break\n",
    "\n",
    "        if len(complaints) >= 4:\n",
    "            break\n",
    "\n",
    "    return complaints if complaints else [\"General quality concerns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0475f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_issues(product_reviews: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Extract specific issues for worst products.\"\"\"\n",
    "    negative_reviews = product_reviews[product_reviews[\"rating\"] <= 2]\n",
    "\n",
    "    if len(negative_reviews) == 0:\n",
    "        return [\"Below average performance\"]\n",
    "\n",
    "    negative_text = \" \".join(negative_reviews[\"clean_review\"].tolist()[:20])\n",
    "\n",
    "    issue_keywords = [\n",
    "        \"stopped working\",\n",
    "        \"broke\",\n",
    "        \"defective\",\n",
    "        \"waste of money\",\n",
    "        \"poor quality\",\n",
    "        \"battery died\",\n",
    "        \"won't charge\",\n",
    "        \"freezes\",\n",
    "    ]\n",
    "\n",
    "    issues = []\n",
    "    sentences = negative_text.split(\".\")\n",
    "\n",
    "    for keyword in issue_keywords:\n",
    "        if keyword in negative_text.lower():\n",
    "            relevant = [\n",
    "                s.strip()\n",
    "                for s in sentences\n",
    "                if keyword in s.lower() and 10 < len(s.strip()) < 90\n",
    "            ]\n",
    "            if relevant:\n",
    "                issues.extend(relevant[:1])\n",
    "\n",
    "        if len(issues) >= 3:\n",
    "            break\n",
    "\n",
    "    return issues if issues else [\"Reliability and quality issues\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288f2ad",
   "metadata": {},
   "source": [
    "## Category_Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c693af",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_top_products(category_data: pd.DataFrame, n_products: int = 3) -> List[Dict]:\n",
    "    \"\"\"Identify top N products based on rating, sentiment, and review volume.\"\"\"\n",
    "    product_stats = category_data.groupby(\"name\").agg(\n",
    "        {\n",
    "            \"rating\": [\"mean\", \"count\"],\n",
    "            \"zero_shot_score\": \"mean\",\n",
    "            \"doRecommend\": \"mean\",\n",
    "        }\n",
    "    ).round(3)\n",
    "\n",
    "    product_stats.columns = [\n",
    "        \"avg_rating\",\n",
    "        \"review_count\",\n",
    "        \"avg_confidence\",\n",
    "        \"recommend_rate\",\n",
    "    ]\n",
    "\n",
    "    product_stats = product_stats[product_stats[\"review_count\"] >= 5]\n",
    "\n",
    "    if len(product_stats) == 0:\n",
    "        return []\n",
    "\n",
    "    max_reviews = product_stats[\"review_count\"].max()\n",
    "    product_stats[\"composite_score\"] = (\n",
    "        0.4 * (product_stats[\"avg_rating\"] / 5.0)\n",
    "        + 0.3 * product_stats[\"avg_confidence\"]\n",
    "        + 0.2 * product_stats[\"recommend_rate\"]\n",
    "        + 0.1 * (np.log(product_stats[\"review_count\"]) / np.log(max_reviews))\n",
    "    )\n",
    "\n",
    "    top_products = product_stats.nlargest(n_products, \"composite_score\")\n",
    "\n",
    "    results = []\n",
    "    for product_name, stats in top_products.iterrows():\n",
    "        product_reviews = category_data[category_data[\"name\"] == product_name]\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"name\": product_name,\n",
    "                \"avg_rating\": stats[\"avg_rating\"],\n",
    "                \"review_count\": int(stats[\"review_count\"]),\n",
    "                \"avg_confidence\": stats[\"avg_confidence\"],\n",
    "                \"recommend_rate\": stats[\"recommend_rate\"],\n",
    "                \"composite_score\": stats[\"composite_score\"],\n",
    "                \"key_features\": extract_key_features(product_reviews),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdbe3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worst_products(category_data: pd.DataFrame, n_products: int = 1) -> List[Dict]:\n",
    "    \"\"\"Identify worst performing products.\"\"\"\n",
    "    product_stats = category_data.groupby(\"name\").agg(\n",
    "        {\n",
    "            \"rating\": [\"mean\", \"count\"],\n",
    "            \"zero_shot_score\": \"mean\",\n",
    "            \"doRecommend\": \"mean\",\n",
    "        }\n",
    "    ).round(3)\n",
    "\n",
    "    product_stats.columns = [\n",
    "        \"avg_rating\",\n",
    "        \"review_count\",\n",
    "        \"avg_confidence\",\n",
    "        \"recommend_rate\",\n",
    "    ]\n",
    "\n",
    "    product_stats = product_stats[product_stats[\"review_count\"] >= 3]\n",
    "\n",
    "    if len(product_stats) == 0:\n",
    "        return []\n",
    "\n",
    "    product_stats[\"negative_score\"] = (\n",
    "        0.5 * (5.0 - product_stats[\"avg_rating\"]) / 5.0\n",
    "        + 0.3 * (1.0 - product_stats[\"avg_confidence\"])\n",
    "        + 0.2 * (1.0 - product_stats[\"recommend_rate\"])\n",
    "    )\n",
    "\n",
    "    worst_products = product_stats.nlargest(n_products, \"negative_score\")\n",
    "\n",
    "    results = []\n",
    "    for product_name, stats in worst_products.iterrows():\n",
    "        product_reviews = category_data[category_data[\"name\"] == product_name]\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"name\": product_name,\n",
    "                \"avg_rating\": stats[\"avg_rating\"],\n",
    "                \"review_count\": int(stats[\"review_count\"]),\n",
    "                \"avg_confidence\": stats[\"avg_confidence\"],\n",
    "                \"recommend_rate\": stats[\"recommend_rate\"],\n",
    "                \"main_issues\": extract_main_issues(product_reviews),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cc653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_category(df: pd.DataFrame, category: str) -> Dict[str, Any]:\n",
    "    \"\"\"Perform comprehensive analysis for a single category.\"\"\"\n",
    "    category_data = df[df[\"zero_shot_label\"] == category]\n",
    "\n",
    "    if len(category_data) == 0:\n",
    "        return None\n",
    "\n",
    "    analysis = {\n",
    "        \"category_name\": category,\n",
    "        \"total_products\": category_data[\"name\"].nunique(),\n",
    "        \"total_reviews\": len(category_data),\n",
    "        \"avg_rating\": category_data[\"rating\"].mean(),\n",
    "        \"avg_confidence\": category_data[\"zero_shot_score\"].mean(),\n",
    "        \"top_products\": get_top_products(category_data),\n",
    "        \"worst_products\": get_worst_products(category_data),\n",
    "        \"common_complaints\": extract_complaints(category_data),\n",
    "    }\n",
    "\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323579fa",
   "metadata": {},
   "source": [
    "## Article Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9769b259",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_article_with_bart(models: Dict, analysis: Dict[str, Any]) -> str:\n",
    "    \"\"\"Generate article using BART for high-quality summarization.\"\"\"\n",
    "    if not analysis:\n",
    "        return \"No analysis available for this category.\"\n",
    "\n",
    "    article_parts = []\n",
    "    article_parts.append(f\"# {analysis['category_name']} - Complete Buying Guide\")\n",
    "    article_parts.append(\n",
    "        f\"*Based on {analysis['total_reviews']} reviews across {analysis['total_products']} products*\"\n",
    "    )\n",
    "    article_parts.append(\n",
    "        f\"**Overall Rating: {analysis['avg_rating']:.1f}/5.0** | \"\n",
    "        f\"**Category Confidence: {analysis['avg_confidence']:.1%}**\"\n",
    "    )\n",
    "\n",
    "    # Top products\n",
    "    if analysis[\"top_products\"]:\n",
    "        article_parts.append(\"\\n## Top 3 Recommended Products\")\n",
    "        for i, product in enumerate(analysis[\"top_products\"], 1):\n",
    "            article_parts.append(f\"\\n### {i}. {product['name']}\")\n",
    "            article_parts.append(\n",
    "                f\"⭐ **{product['avg_rating']:.1f}/5.0** ({product['review_count']} reviews)\"\n",
    "            )\n",
    "            article_parts.append(\n",
    "                f\"✅ **{product['recommend_rate']:.1%}** recommend this product\"\n",
    "            )\n",
    "            article_parts.append(\"\\n**Key Features:**\")\n",
    "            for feature in product[\"key_features\"]:\n",
    "                article_parts.append(f\"- {feature}\")\n",
    "\n",
    "    # Complaints\n",
    "    if analysis[\"common_complaints\"]:\n",
    "        article_parts.append(\"\\n## Common Issues Across Category\")\n",
    "        for complaint in analysis[\"common_complaints\"]:\n",
    "            article_parts.append(f\"- {complaint}\")\n",
    "\n",
    "    # Worst products\n",
    "    if analysis[\"worst_products\"]:\n",
    "        article_parts.append(\"\\n## Products to Avoid\")\n",
    "        for product in analysis[\"worst_products\"]:\n",
    "            article_parts.append(f\"\\n### {product['name']}\")\n",
    "            article_parts.append(\n",
    "                f\"⭐ **{product['avg_rating']:.1f}/5.0** ({product['review_count']} reviews)\"\n",
    "            )\n",
    "            article_parts.append(\"\\n**Main Issues:**\")\n",
    "            for issue in product[\"main_issues\"]:\n",
    "                article_parts.append(f\"- {issue}\")\n",
    "\n",
    "    # Recommendation\n",
    "    if analysis[\"top_products\"]:\n",
    "        best_product = analysis[\"top_products\"][0]\n",
    "        article_parts.append(\"\\n## Bottom Line\")\n",
    "        article_parts.append(\n",
    "            f\"**Best Choice:** {best_product['name']} leads with \"\n",
    "            f\"{best_product['avg_rating']:.1f}/5.0 stars and \"\n",
    "            f\"{best_product['recommend_rate']:.1%} recommendation rate.\"\n",
    "        )\n",
    "        article_parts.append(\n",
    "            f\"This category shows {'strong' if analysis['avg_rating'] >= 4.0 else 'moderate'} \"\n",
    "            f\"overall customer satisfaction.\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(article_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de2e45",
   "metadata": {},
   "source": [
    "## Pipeline Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffeb861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_categories(models: Dict, df: pd.DataFrame) -> Dict[str, str]:\n",
    "    \"\"\"Process all categories and generate articles.\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Generating articles for all categories...\")\n",
    "\n",
    "    categories = df[\"zero_shot_label\"].unique()\n",
    "    articles = {}\n",
    "\n",
    "    for i, category in enumerate(categories, 1):\n",
    "        if pd.isna(category):\n",
    "            continue\n",
    "\n",
    "        category_start = time.time()\n",
    "        analysis = analyze_category(df, category)\n",
    "\n",
    "        if analysis:\n",
    "            article = generate_article_with_bart(models, analysis)\n",
    "            articles[category] = article\n",
    "            category_time = time.time() - category_start\n",
    "            print(f\"[{i}/{len(categories)}] {category}: {category_time:.1f}s\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"All articles generated in {total_time:.1f} seconds\")\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f5cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_articles(articles: Dict[str, str], output_dir: str = \"generated_articles/\"):\n",
    "    \"\"\"Save articles to Markdown files.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for category, article in articles.items():\n",
    "        filename = re.sub(r\"[^\\w\\s-]\", \"\", category).strip()\n",
    "        filename = re.sub(r\"[-\\s]+\", \"_\", filename).lower()\n",
    "        filepath = os.path.join(output_dir, f\"{filename}_buying_guide.md\")\n",
    "\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25ed3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_dashboard(df: pd.DataFrame, articles: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"Create and display summary visualizations.\"\"\"\n",
    "    categories = df[\"zero_shot_label\"].unique()\n",
    "    category_stats = []\n",
    "\n",
    "    for category in categories:\n",
    "        if pd.isna(category):\n",
    "            continue\n",
    "\n",
    "        cat_data = df[df[\"zero_shot_label\"] == category]\n",
    "        category_stats.append(\n",
    "            {\n",
    "                \"category\": category,\n",
    "                \"avg_rating\": cat_data[\"rating\"].mean(),\n",
    "                \"avg_confidence\": cat_data[\"zero_shot_score\"].mean(),\n",
    "                \"review_count\": len(cat_data),\n",
    "                \"product_count\": cat_data[\"name\"].nunique(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    stats_df = pd.DataFrame(category_stats)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    axes[0, 0].barh(stats_df[\"category\"], stats_df[\"avg_rating\"], color=\"skyblue\")\n",
    "    axes[0, 0].set_title(\"Average Rating by Category\")\n",
    "    axes[0, 0].set_xlabel(\"Rating (1-5)\")\n",
    "\n",
    "    axes[0, 1].barh(stats_df[\"category\"], stats_df[\"avg_confidence\"], color=\"lightgreen\")\n",
    "    axes[0, 1].set_title(\"Zero-Shot Classification Confidence\")\n",
    "    axes[0, 1].set_xlabel(\"Confidence Score\")\n",
    "\n",
    "    axes[1, 0].barh(stats_df[\"category\"], stats_df[\"review_count\"], color=\"orange\")\n",
    "    axes[1, 0].set_title(\"Number of Reviews\")\n",
    "    axes[1, 0].set_xlabel(\"Review Count\")\n",
    "\n",
    "    axes[1, 1].barh(stats_df[\"category\"], stats_df[\"product_count\"], color=\"purple\")\n",
    "    axes[1, 1].set_title(\"Number of Unique Products\")\n",
    "    axes[1, 1].set_xlabel(\"Product Count\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96ddc2",
   "metadata": {},
   "source": [
    "## Main Execution Funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3880eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf08a59451154c0195c714e72c0773ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397c8fc5833d41518687ea354b414876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384c3ed410334c16b31419d7c0137cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1835fa6b2031482eb5671d3b5f969b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2101b979dad74ec1bffac529282610ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92c6ee523df48fba9fc8d1748f31039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded in 7.9 seconds\n",
      "Loading data from /content/reranker_products.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/reranker_products.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m models, df, articles, summary_stats\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Execute the pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m models, df, articles, stats = run_summarization_pipeline()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mrun_summarization_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Step 2: Load data (~30 seconds)\u001b[39;00m\n\u001b[32m     12\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33m/content/reranker_products.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df = load_and_prepare_data(file_path)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Step 3: Generate articles (4-6 minutes)\u001b[39;00m\n\u001b[32m     16\u001b[39m articles = process_all_categories(models, df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mload_and_prepare_data\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mLoad and validate product reviews dataset.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mRuntime: ~30 seconds.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = pd.read_csv(file_path)\n\u001b[32m      9\u001b[39m required_cols = [\u001b[33m\"\u001b[39m\u001b[33mzero_shot_label\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mzero_shot_score\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrating\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m missing_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m required_cols \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\project_nlp_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\project_nlp_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = TextFileReader(filepath_or_buffer, **kwds)\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\project_nlp_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28mself\u001b[39m._make_engine(f, \u001b[38;5;28mself\u001b[39m.engine)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\project_nlp_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = get_handle(\n\u001b[32m   1881\u001b[39m     f,\n\u001b[32m   1882\u001b[39m     mode,\n\u001b[32m   1883\u001b[39m     encoding=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1884\u001b[39m     compression=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1885\u001b[39m     memory_map=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mmemory_map\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m   1886\u001b[39m     is_text=is_text,\n\u001b[32m   1887\u001b[39m     errors=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mencoding_errors\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1888\u001b[39m     storage_options=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1889\u001b[39m )\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\project_nlp_env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/reranker_products.csv'"
     ]
    }
   ],
   "source": [
    "def run_summarization_pipeline():\n",
    "    \"\"\"\n",
    "    Complete pipeline execution.\n",
    "    Total Estimated Runtime: 8-12 minutes on T4 GPU\n",
    "    \"\"\"\n",
    "    pipeline_start = time.time()\n",
    "    \n",
    "    # Step 1: Load models (2-3 minutes)\n",
    "    models = load_models()\n",
    "    \n",
    "    # Step 2: Load data (~30 seconds)\n",
    "    file_path = \"/content/reranker_products.csv\"\n",
    "    df = load_and_prepare_data(file_path)\n",
    "    \n",
    "    # Step 3: Generate articles (4-6 minutes)\n",
    "    articles = process_all_categories(models, df)\n",
    "    \n",
    "    # Step 4: Save results (~10 seconds)\n",
    "    save_articles(articles)\n",
    "    \n",
    "    # Step 5: Create dashboard (~20 seconds)\n",
    "    summary_stats = create_summary_dashboard(df, articles)\n",
    "    \n",
    "    total_time = time.time() - pipeline_start\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total Runtime: {total_time/60:.1f} minutes\")\n",
    "    print(f\"Generated {len(articles)} buying guides\")\n",
    "    print(\"Articles saved to 'generated_articles/' directory\")\n",
    "    \n",
    "    # Show sample article preview\n",
    "    if articles:\n",
    "        sample_category = list(articles.keys())[0]\n",
    "        print(f\"\\nSample preview ({sample_category}):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(articles[sample_category][:400] + \"...\")\n",
    "    \n",
    "    return models, df, articles, summary_stats\n",
    "\n",
    "# Execute the pipeline\n",
    "models, df, articles, stats = run_summarization_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ee4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "project_nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
