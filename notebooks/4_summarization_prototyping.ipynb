{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c594e3eb",
   "metadata": {},
   "source": [
    "## Product Review Summarization and Buying Guide Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce3d46",
   "metadata": {},
   "source": [
    "This script generates comprehensive product review articles using:\n",
    "- BART for high-quality summarization\n",
    "- T5 for structured text generation\n",
    "- RoBERTa for sentiment validation\n",
    "\n",
    "Pipeline steps:\n",
    "1. Load NLP models\n",
    "2. Load and preprocess review data\n",
    "3. Analyze categories and products\n",
    "4. Generate structured buying guides\n",
    "5. Save articles to Markdown\n",
    "6. Create a summary dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff3c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    pipeline,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    BartForConditionalGeneration,\n",
    "    BartTokenizer,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d755627",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af90199",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff025d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_models() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load all required NLP models for summarization and analysis.\n",
    "    Runtime: ~2-3 minutes on T4 GPU.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Loading models...\")\n",
    "\n",
    "    # BART for summarization\n",
    "    bart_model_name = \"facebook/bart-large-cnn\"\n",
    "    bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
    "    bart_model = BartForConditionalGeneration.from_pretrained(\n",
    "        bart_model_name\n",
    "    ).to(device)\n",
    "\n",
    "    # T5 for structured generation\n",
    "    t5_model_name = \"t5-small\"\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "    t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name).to(device)\n",
    "\n",
    "    # Summarization pipeline\n",
    "    summarizer = pipeline(\n",
    "        \"summarization\",\n",
    "        model=bart_model,\n",
    "        tokenizer=bart_tokenizer,\n",
    "        device=0 if torch.cuda.is_available() else -1,\n",
    "        max_length=130,\n",
    "        min_length=40,\n",
    "        do_sample=False,\n",
    "    )\n",
    "\n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"Models loaded in {load_time:.1f} seconds\")\n",
    "\n",
    "    return {\n",
    "        \"bart_model\": bart_model,\n",
    "        \"bart_tokenizer\": bart_tokenizer,\n",
    "        \"t5_model\": t5_model,\n",
    "        \"t5_tokenizer\": t5_tokenizer,\n",
    "        \"summarizer\": summarizer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1727db0",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939822b9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text data efficiently.\"\"\"\n",
    "    if pd.isna(text) or str(text) == \"nan\":\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", str(text))  # Remove HTML\n",
    "    text = re.sub(r\"[^\\w\\s.,!?-]\", \" \", text)  # Keep basic punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize whitespace\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a15415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and validate product reviews dataset.\n",
    "    Runtime: ~30 seconds.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    required_cols = [\"zero_shot_label\", \"zero_shot_score\", \"name\", \"rating\", \"text\"]\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "\n",
    "    df[\"clean_review\"] = df[\"text\"].astype(str).apply(clean_text)\n",
    "    df = df[\n",
    "        (df[\"clean_review\"].str.len() > 20) & (df[\"clean_review\"] != \"\")\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    print(\n",
    "        f\"Loaded {len(df)} reviews across {df['zero_shot_label'].nunique()} categories\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b8239",
   "metadata": {},
   "source": [
    "## Product Analysis Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f985d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_key_features(product_reviews: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Extract key differentiating features from positive reviews.\"\"\"\n",
    "    positive_reviews = product_reviews[product_reviews[\"rating\"] >= 4]\n",
    "\n",
    "    if len(positive_reviews) == 0:\n",
    "        return [\"Standard features\"]\n",
    "\n",
    "    sample_size = min(15, len(positive_reviews))\n",
    "    sample_text = \" \".join(\n",
    "        positive_reviews[\"clean_review\"].sample(sample_size).tolist()\n",
    "    )\n",
    "\n",
    "    feature_keywords = [\n",
    "        \"display\",\n",
    "        \"screen\",\n",
    "        \"battery\",\n",
    "        \"storage\",\n",
    "        \"performance\",\n",
    "        \"camera\",\n",
    "        \"sound\",\n",
    "        \"design\",\n",
    "        \"fast\",\n",
    "        \"easy\",\n",
    "        \"quality\",\n",
    "        \"durable\",\n",
    "        \"portable\",\n",
    "        \"connectivity\",\n",
    "    ]\n",
    "\n",
    "    features = []\n",
    "    sentences = sample_text.split(\".\")\n",
    "\n",
    "    for keyword in feature_keywords:\n",
    "        relevant_sentences = [\n",
    "            s.strip()\n",
    "            for s in sentences\n",
    "            if keyword in s.lower() and 10 < len(s.strip()) < 80\n",
    "        ]\n",
    "\n",
    "        if relevant_sentences:\n",
    "            features.extend(relevant_sentences[:1])\n",
    "\n",
    "        if len(features) >= 3:\n",
    "            break\n",
    "\n",
    "    return features[:3] if features else [\"Solid overall performance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeda9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_complaints(category_data: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Extract common complaints from negative reviews.\"\"\"\n",
    "    negative_reviews = category_data[category_data[\"rating\"] <= 2]\n",
    "\n",
    "    if len(negative_reviews) == 0:\n",
    "        return [\"No significant complaints\"]\n",
    "\n",
    "    sample_size = min(50, len(negative_reviews))\n",
    "    negative_text = \" \".join(\n",
    "        negative_reviews[\"clean_review\"].sample(sample_size).tolist()\n",
    "    )\n",
    "\n",
    "    complaint_patterns = [\n",
    "        (\"battery\", [\"battery\", \"charging\", \"power\"]),\n",
    "        (\"quality\", [\"cheap\", \"flimsy\", \"poor quality\", \"broke\"]),\n",
    "        (\"performance\", [\"slow\", \"lag\", \"freeze\", \"crash\"]),\n",
    "        (\"connectivity\", [\"wifi\", \"connection\", \"network\"]),\n",
    "        (\"customer service\", [\"support\", \"service\", \"warranty\"]),\n",
    "    ]\n",
    "\n",
    "    complaints = []\n",
    "    sentences = negative_text.split(\".\")\n",
    "\n",
    "    for category, keywords in complaint_patterns:\n",
    "        for keyword in keywords:\n",
    "            if keyword in negative_text.lower():\n",
    "                relevant = [\n",
    "                    s.strip()\n",
    "                    for s in sentences\n",
    "                    if keyword in s.lower() and 15 < len(s.strip()) < 100\n",
    "                ]\n",
    "                if relevant:\n",
    "                    complaints.append(f\"{category.title()}: {relevant[0]}\")\n",
    "                    break\n",
    "\n",
    "        if len(complaints) >= 4:\n",
    "            break\n",
    "\n",
    "    return complaints if complaints else [\"General quality concerns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0475f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_issues(product_reviews: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Extract specific issues for worst products.\"\"\"\n",
    "    negative_reviews = product_reviews[product_reviews[\"rating\"] <= 2]\n",
    "\n",
    "    if len(negative_reviews) == 0:\n",
    "        return [\"Below average performance\"]\n",
    "\n",
    "    negative_text = \" \".join(negative_reviews[\"clean_review\"].tolist()[:20])\n",
    "\n",
    "    issue_keywords = [\n",
    "        \"stopped working\",\n",
    "        \"broke\",\n",
    "        \"defective\",\n",
    "        \"waste of money\",\n",
    "        \"poor quality\",\n",
    "        \"battery died\",\n",
    "        \"won't charge\",\n",
    "        \"freezes\",\n",
    "    ]\n",
    "\n",
    "    issues = []\n",
    "    sentences = negative_text.split(\".\")\n",
    "\n",
    "    for keyword in issue_keywords:\n",
    "        if keyword in negative_text.lower():\n",
    "            relevant = [\n",
    "                s.strip()\n",
    "                for s in sentences\n",
    "                if keyword in s.lower() and 10 < len(s.strip()) < 90\n",
    "            ]\n",
    "            if relevant:\n",
    "                issues.extend(relevant[:1])\n",
    "\n",
    "        if len(issues) >= 3:\n",
    "            break\n",
    "\n",
    "    return issues if issues else [\"Reliability and quality issues\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288f2ad",
   "metadata": {},
   "source": [
    "## Category_Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c693af",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_top_products(category_data: pd.DataFrame, n_products: int = 3) -> List[Dict]:\n",
    "    \"\"\"Identify top N products based on rating, sentiment, and review volume.\"\"\"\n",
    "    product_stats = category_data.groupby(\"name\").agg(\n",
    "        {\n",
    "            \"rating\": [\"mean\", \"count\"],\n",
    "            \"zero_shot_score\": \"mean\",\n",
    "            \"doRecommend\": \"mean\",\n",
    "        }\n",
    "    ).round(3)\n",
    "\n",
    "    product_stats.columns = [\n",
    "        \"avg_rating\",\n",
    "        \"review_count\",\n",
    "        \"avg_confidence\",\n",
    "        \"recommend_rate\",\n",
    "    ]\n",
    "\n",
    "    product_stats = product_stats[product_stats[\"review_count\"] >= 5]\n",
    "\n",
    "    if len(product_stats) == 0:\n",
    "        return []\n",
    "\n",
    "    max_reviews = product_stats[\"review_count\"].max()\n",
    "    product_stats[\"composite_score\"] = (\n",
    "        0.4 * (product_stats[\"avg_rating\"] / 5.0)\n",
    "        + 0.3 * product_stats[\"avg_confidence\"]\n",
    "        + 0.2 * product_stats[\"recommend_rate\"]\n",
    "        + 0.1 * (np.log(product_stats[\"review_count\"]) / np.log(max_reviews))\n",
    "    )\n",
    "\n",
    "    top_products = product_stats.nlargest(n_products, \"composite_score\")\n",
    "\n",
    "    results = []\n",
    "    for product_name, stats in top_products.iterrows():\n",
    "        product_reviews = category_data[category_data[\"name\"] == product_name]\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"name\": product_name,\n",
    "                \"avg_rating\": stats[\"avg_rating\"],\n",
    "                \"review_count\": int(stats[\"review_count\"]),\n",
    "                \"avg_confidence\": stats[\"avg_confidence\"],\n",
    "                \"recommend_rate\": stats[\"recommend_rate\"],\n",
    "                \"composite_score\": stats[\"composite_score\"],\n",
    "                \"key_features\": extract_key_features(product_reviews),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdbe3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worst_products(category_data: pd.DataFrame, n_products: int = 1) -> List[Dict]:\n",
    "    \"\"\"Identify worst performing products.\"\"\"\n",
    "    product_stats = category_data.groupby(\"name\").agg(\n",
    "        {\n",
    "            \"rating\": [\"mean\", \"count\"],\n",
    "            \"zero_shot_score\": \"mean\",\n",
    "            \"doRecommend\": \"mean\",\n",
    "        }\n",
    "    ).round(3)\n",
    "\n",
    "    product_stats.columns = [\n",
    "        \"avg_rating\",\n",
    "        \"review_count\",\n",
    "        \"avg_confidence\",\n",
    "        \"recommend_rate\",\n",
    "    ]\n",
    "\n",
    "    product_stats = product_stats[product_stats[\"review_count\"] >= 3]\n",
    "\n",
    "    if len(product_stats) == 0:\n",
    "        return []\n",
    "\n",
    "    product_stats[\"negative_score\"] = (\n",
    "        0.5 * (5.0 - product_stats[\"avg_rating\"]) / 5.0\n",
    "        + 0.3 * (1.0 - product_stats[\"avg_confidence\"])\n",
    "        + 0.2 * (1.0 - product_stats[\"recommend_rate\"])\n",
    "    )\n",
    "\n",
    "    worst_products = product_stats.nlargest(n_products, \"negative_score\")\n",
    "\n",
    "    results = []\n",
    "    for product_name, stats in worst_products.iterrows():\n",
    "        product_reviews = category_data[category_data[\"name\"] == product_name]\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"name\": product_name,\n",
    "                \"avg_rating\": stats[\"avg_rating\"],\n",
    "                \"review_count\": int(stats[\"review_count\"]),\n",
    "                \"avg_confidence\": stats[\"avg_confidence\"],\n",
    "                \"recommend_rate\": stats[\"recommend_rate\"],\n",
    "                \"main_issues\": extract_main_issues(product_reviews),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cc653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_category(df: pd.DataFrame, category: str) -> Dict[str, Any]:\n",
    "    \"\"\"Perform comprehensive analysis for a single category.\"\"\"\n",
    "    category_data = df[df[\"zero_shot_label\"] == category]\n",
    "\n",
    "    if len(category_data) == 0:\n",
    "        return None\n",
    "\n",
    "    analysis = {\n",
    "        \"category_name\": category,\n",
    "        \"total_products\": category_data[\"name\"].nunique(),\n",
    "        \"total_reviews\": len(category_data),\n",
    "        \"avg_rating\": category_data[\"rating\"].mean(),\n",
    "        \"avg_confidence\": category_data[\"zero_shot_score\"].mean(),\n",
    "        \"top_products\": get_top_products(category_data),\n",
    "        \"worst_products\": get_worst_products(category_data),\n",
    "        \"common_complaints\": extract_complaints(category_data),\n",
    "    }\n",
    "\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323579fa",
   "metadata": {},
   "source": [
    "## Article Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9769b259",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_article_with_bart(models: Dict, analysis: Dict[str, Any]) -> str:\n",
    "    \"\"\"Generate article using BART for high-quality summarization.\"\"\"\n",
    "    if not analysis:\n",
    "        return \"No analysis available for this category.\"\n",
    "\n",
    "    article_parts = []\n",
    "    article_parts.append(f\"# {analysis['category_name']} - Complete Buying Guide\")\n",
    "    article_parts.append(\n",
    "        f\"*Based on {analysis['total_reviews']} reviews across {analysis['total_products']} products*\"\n",
    "    )\n",
    "    article_parts.append(\n",
    "        f\"**Overall Rating: {analysis['avg_rating']:.1f}/5.0** | \"\n",
    "        f\"**Category Confidence: {analysis['avg_confidence']:.1%}**\"\n",
    "    )\n",
    "\n",
    "    # Top products\n",
    "    if analysis[\"top_products\"]:\n",
    "        article_parts.append(\"\\n## Top 3 Recommended Products\")\n",
    "        for i, product in enumerate(analysis[\"top_products\"], 1):\n",
    "            article_parts.append(f\"\\n### {i}. {product['name']}\")\n",
    "            article_parts.append(\n",
    "                f\"⭐ **{product['avg_rating']:.1f}/5.0** ({product['review_count']} reviews)\"\n",
    "            )\n",
    "            article_parts.append(\n",
    "                f\"✅ **{product['recommend_rate']:.1%}** recommend this product\"\n",
    "            )\n",
    "            article_parts.append(\"\\n**Key Features:**\")\n",
    "            for feature in product[\"key_features\"]:\n",
    "                article_parts.append(f\"- {feature}\")\n",
    "\n",
    "    # Complaints\n",
    "    if analysis[\"common_complaints\"]:\n",
    "        article_parts.append(\"\\n## Common Issues Across Category\")\n",
    "        for complaint in analysis[\"common_complaints\"]:\n",
    "            article_parts.append(f\"- {complaint}\")\n",
    "\n",
    "    # Worst products\n",
    "    if analysis[\"worst_products\"]:\n",
    "        article_parts.append(\"\\n## Products to Avoid\")\n",
    "        for product in analysis[\"worst_products\"]:\n",
    "            article_parts.append(f\"\\n### {product['name']}\")\n",
    "            article_parts.append(\n",
    "                f\"⭐ **{product['avg_rating']:.1f}/5.0** ({product['review_count']} reviews)\"\n",
    "            )\n",
    "            article_parts.append(\"\\n**Main Issues:**\")\n",
    "            for issue in product[\"main_issues\"]:\n",
    "                article_parts.append(f\"- {issue}\")\n",
    "\n",
    "    # Recommendation\n",
    "    if analysis[\"top_products\"]:\n",
    "        best_product = analysis[\"top_products\"][0]\n",
    "        article_parts.append(\"\\n## Bottom Line\")\n",
    "        article_parts.append(\n",
    "            f\"**Best Choice:** {best_product['name']} leads with \"\n",
    "            f\"{best_product['avg_rating']:.1f}/5.0 stars and \"\n",
    "            f\"{best_product['recommend_rate']:.1%} recommendation rate.\"\n",
    "        )\n",
    "        article_parts.append(\n",
    "            f\"This category shows {'strong' if analysis['avg_rating'] >= 4.0 else 'moderate'} \"\n",
    "            f\"overall customer satisfaction.\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(article_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de2e45",
   "metadata": {},
   "source": [
    "## Pipeline Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffeb861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_categories(models: Dict, df: pd.DataFrame) -> Dict[str, str]:\n",
    "    \"\"\"Process all categories and generate articles.\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Generating articles for all categories...\")\n",
    "\n",
    "    categories = df[\"zero_shot_label\"].unique()\n",
    "    articles = {}\n",
    "\n",
    "    for i, category in enumerate(categories, 1):\n",
    "        if pd.isna(category):\n",
    "            continue\n",
    "\n",
    "        category_start = time.time()\n",
    "        analysis = analyze_category(df, category)\n",
    "\n",
    "        if analysis:\n",
    "            article = generate_article_with_bart(models, analysis)\n",
    "            articles[category] = article\n",
    "            category_time = time.time() - category_start\n",
    "            print(f\"[{i}/{len(categories)}] {category}: {category_time:.1f}s\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"All articles generated in {total_time:.1f} seconds\")\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f5cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_articles(articles: Dict[str, str], output_dir: str = \"generated_articles/\"):\n",
    "    \"\"\"Save articles to Markdown files.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for category, article in articles.items():\n",
    "        filename = re.sub(r\"[^\\w\\s-]\", \"\", category).strip()\n",
    "        filename = re.sub(r\"[-\\s]+\", \"_\", filename).lower()\n",
    "        filepath = os.path.join(output_dir, f\"{filename}_buying_guide.md\")\n",
    "\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25ed3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_dashboard(df: pd.DataFrame, articles: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"Create and display summary visualizations.\"\"\"\n",
    "    categories = df[\"zero_shot_label\"].unique()\n",
    "    category_stats = []\n",
    "\n",
    "    for category in categories:\n",
    "        if pd.isna(category):\n",
    "            continue\n",
    "\n",
    "        cat_data = df[df[\"zero_shot_label\"] == category]\n",
    "        category_stats.append(\n",
    "            {\n",
    "                \"category\": category,\n",
    "                \"avg_rating\": cat_data[\"rating\"].mean(),\n",
    "                \"avg_confidence\": cat_data[\"zero_shot_score\"].mean(),\n",
    "                \"review_count\": len(cat_data),\n",
    "                \"product_count\": cat_data[\"name\"].nunique(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    stats_df = pd.DataFrame(category_stats)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    axes[0, 0].barh(stats_df[\"category\"], stats_df[\"avg_rating\"], color=\"skyblue\")\n",
    "    axes[0, 0].set_title(\"Average Rating by Category\")\n",
    "    axes[0, 0].set_xlabel(\"Rating (1-5)\")\n",
    "\n",
    "    axes[0, 1].barh(stats_df[\"category\"], stats_df[\"avg_confidence\"], color=\"lightgreen\")\n",
    "    axes[0, 1].set_title(\"Zero-Shot Classification Confidence\")\n",
    "    axes[0, 1].set_xlabel(\"Confidence Score\")\n",
    "\n",
    "    axes[1, 0].barh(stats_df[\"category\"], stats_df[\"review_count\"], color=\"orange\")\n",
    "    axes[1, 0].set_title(\"Number of Reviews\")\n",
    "    axes[1, 0].set_xlabel(\"Review Count\")\n",
    "\n",
    "    axes[1, 1].barh(stats_df[\"category\"], stats_df[\"product_count\"], color=\"purple\")\n",
    "    axes[1, 1].set_title(\"Number of Unique Products\")\n",
    "    axes[1, 1].set_xlabel(\"Product Count\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96ddc2",
   "metadata": {},
   "source": [
    "## Main Execution Funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3880eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m models, df, articles, summary_stats\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Execute the pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m models, df, articles, stats = run_summarization_pipeline()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mrun_summarization_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m pipeline_start = time.time()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Step 1: Load models (2-3 minutes)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m models = load_models()\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Step 2: Load data (~30 seconds)\u001b[39;00m\n\u001b[32m     12\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33m/content/reranker_products.csv\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mload_models\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# T5 for structured generation\u001b[39;00m\n\u001b[32m     17\u001b[39m t5_model_name = \u001b[33m\"\u001b[39m\u001b[33mt5-small\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n\u001b[32m     19\u001b[39m t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name).to(device)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Summarization pipeline\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\project_nlp_env\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1840\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m._backends)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\project_nlp_env\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1828\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   1826\u001b[39m failed = [msg.format(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[32m   1827\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m1828\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "def run_summarization_pipeline():\n",
    "    \"\"\"\n",
    "    Complete pipeline execution.\n",
    "    Total Estimated Runtime: 8-12 minutes on T4 GPU\n",
    "    \"\"\"\n",
    "    pipeline_start = time.time()\n",
    "    \n",
    "    # Step 1: Load models (2-3 minutes)\n",
    "    models = load_models()\n",
    "    \n",
    "    # Step 2: Load data (~30 seconds)\n",
    "    file_path = \"/content/reranker_products.csv\"\n",
    "    df = load_and_prepare_data(file_path)\n",
    "    \n",
    "    # Step 3: Generate articles (4-6 minutes)\n",
    "    articles = process_all_categories(models, df)\n",
    "    \n",
    "    # Step 4: Save results (~10 seconds)\n",
    "    save_articles(articles)\n",
    "    \n",
    "    # Step 5: Create dashboard (~20 seconds)\n",
    "    summary_stats = create_summary_dashboard(df, articles)\n",
    "    \n",
    "    total_time = time.time() - pipeline_start\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total Runtime: {total_time/60:.1f} minutes\")\n",
    "    print(f\"Generated {len(articles)} buying guides\")\n",
    "    print(\"Articles saved to 'generated_articles/' directory\")\n",
    "    \n",
    "    # Show sample article preview\n",
    "    if articles:\n",
    "        sample_category = list(articles.keys())[0]\n",
    "        print(f\"\\nSample preview ({sample_category}):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(articles[sample_category][:400] + \"...\")\n",
    "    \n",
    "    return models, df, articles, summary_stats\n",
    "\n",
    "# Execute the pipeline\n",
    "models, df, articles, stats = run_summarization_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ee4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "project_nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
